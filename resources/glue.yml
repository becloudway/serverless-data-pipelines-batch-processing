Resources:
  DeliveryBucketCrawlerRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: DeliveryBucketCrawlerRole
      AssumeRolePolicyDocument:
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - glue.amazonaws.com
            Action:
              - sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole
      Policies:
        - PolicyName: DeliveryBucketCrawlerPolicy
          PolicyDocument:
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: "*"
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                Resource:
                  - Fn::Join:
                      - ""
                      - - "arn:aws:s3:::"
                        - !ImportValue sls-data-pipelines-dev-TrafficEventsDeliveryBucketName
                        - "/destination-parquet*"
  DeliveryBucketCrawler:
    Type: AWS::Glue::Crawler
    Properties:
      Role: !GetAtt DeliveryBucketCrawlerRole.Arn
      DatabaseName: ${self:custom.Database}
      TablePrefix: sls_data_pipelines_batch_
      Name: sls-data-pipelines-delivery-bucket-crawler
      Targets:
        S3Targets:
          - Path:
              Fn::Join:
                - ""
                - - !ImportValue sls-data-pipelines-dev-TrafficEventsDeliveryBucketName
                  - "/destination-parquet"
  BatchTransformedTable:
    Type: AWS::Glue::Table
    Properties:
      CatalogId: "#{AWS::AccountId}"
      DatabaseName: ${self:custom.Database}
      TableInput:
        Name: sls_data_pipelines_batch_transformed
        TableType: EXTERNAL_TABLE
        Parameters:
          orc.compress: SNAPPY
          has_encrypted_data: false
          EXTERNAL: TRUE
        PartitionKeys:
          - {Name: year, Type: bigint}
          - {Name: month, Type: bigint}
          - {Name: day, Type: bigint}
          - {Name: hour, Type: bigint}
        StorageDescriptor:
          Columns:
            - {Name: uniqueid, Type: int}
            - {Name: recordtimestamp, Type: bigint}
            - {Name: currentspeed, Type: double}
            - {Name: bezettingsgraad, Type: int}
            - {Name: previousspeed, Type: double}
            - {Name: trafficjamindicator, Type: int}
            - {Name: trafficintensityclass2, Type: int}
            - {Name: trafficintensityclass3, Type: int}
            - {Name: trafficintensityclass4, Type: int}
            - {Name: trafficintensityclass5, Type: int}
            - {Name: speeddiffindicator, Type: int}
            - {Name: avgspeed2minutes, Type: double}
            - {Name: avgspeed10minutes, Type: double}
          Compressed: True
          InputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
          OutputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
          Location:
            Fn::Join:
              - ""
              - - "s3://"
                - !ImportValue sls-data-pipelines-dev-TrafficEventsDeliveryBucketName
                - "/batch-transformed"
          SerdeInfo:
            Name: sls_data_pipelines_batch_transformed
            SerializationLibrary: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
